import os
import re
import json
import nltk
import inputTerms
from inputTerms import input_terms
from inputVocab import input_vocab
from nltk import word_tokenize

termFilePath = "/home/manikya/Documents/NLP/Data/SemEval18-Task9/trial/data/1A.english.trial.data_O.txt"
vocabFilePath = "/home/manikya/Documents/NLP/Data/SemEval18-Task9/vocabulary/1A.english.vocabulary_0.txt"

# print json.dumps(input_terms)
# print "---------------------------"
# print json.dumps(input_vocab)

# def ngram_index(words, ngram):
#     return list(nltk.ngrams(words, len(ngram))).index(tuple(ngram))
# int_position = ngram_index("this is a cat in the cage with a dog in another cage in the", "in the")
# print ("Postion is : %d" % int_position)

def preprocess(fullfilepath, filename, filepath):
    inputF = open(fullfilepath, 'r')
    outputfilename = re.sub(r'.possf2', r'.txt', filename)
    outputFile = os.path.join(filepath, outputfilename)
    outputF = open(outputFile, 'w')

    input_terms = []
    matchStarSt = re.compile(r'^\*\*')
    # matchStarEn = re.compile(r'\*\*$')


    for line in inputF:
        finalLine = ""
        lineleft = re.sub(r'(\w*_NN[A-Z]*)', r'**\1**', line)
        tokens = word_tokenize(lineleft)
        for word in tokens:
            mS = re.match(matchStarSt,word)
            # mE = re.match(matchStarEn,word)
            if mS:
                # print word
                finalLine = finalLine + " " + word + " "

        # print finalLine
        lineUnTag = re.sub(r'_[A-Z]+ ', r' ', finalLine)
        lineUnTag = lineUnTag.lower()
        # tokensTag = word_tokenize(line)
        # tokendUnTag = word_tokenize(lineUnTag)
        outputF.write(lineUnTag)



# outputF.write(json.dumps(input_terms))


for file in os.listdir("/home/manikya/Documents/NLP/Data/"):
    if file.endswith(".possf2"):
        filename = (os.path.join("/home/manikya/Documents/NLP/Data/", file))
        preprocess(filename, file, "/home/manikya/Documents/NLP/Data/")